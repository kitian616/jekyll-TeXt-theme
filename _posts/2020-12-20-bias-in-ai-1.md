---
title: 'BIAS in AI (1)'
date: 2020-12-20 12:21:12
tags: [ç¤¾ä¼šåè§,å­¦æœ¯ç ”ç©¶,å°å°åˆ†äº«]
---
![](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/BIAS%20IN%20AI.png)

> When we say algorithm fairness, what we're talking about?

å½“æˆ‘ä»¬åœ¨æåŠç®—æ³•å…¬å¹³æ€§çš„æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿ

æ¥æºï¼šSafety, Bias, and Fairness (guest lecture by *[Margaret Mitchell](http://www.m-mitchell.com/)*) [[slides](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf)] [[video](https://www.youtube.com/watch?v=XR8YSRcuVLE&feature=youtu.be)]
Stanford / Winter 2019, [CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)

<!--more-->

AIä¸­çš„biaså…¶å®æ˜¯ç›¸å½“å¤šä¸”å¹¿æ³›çš„ï¼Œæœ€æ™®éçš„æ˜¯ä¸€ä¸ªæœºå™¨ç¿»è¯‘çš„ä¾‹å­ï¼š

![åœŸè€³å…¶è¯­å’Œè‹±è¯­çš„äº’è¯‘](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/bias%20in%20MT.jpg)

è¿™æ˜¯ä¸€ä¸ªåœŸè€³å…¶è¯­ä¸è‹±è¯­äº’è¯‘çš„ä¾‹å­ï¼Œæœºå™¨ä¼šæŠŠåŸæœ¬æ˜¯æ— æ€§åˆ«çš„ä»£è¯ç¿»è¯‘ä¸ºå…·æœ‰æ€§åˆ«çš„ä»£è¯ã€‚

æœ€è¿‘åœ¨é‡æ–°çœ‹CS224nï¼Œè¯¾ç¨‹ä¹Ÿæ­£å¥½é‚€è¯·åˆ°äº†Google AIçš„ç ”ç©¶å­¦è€…Margaret Mitchellä½œå…³äºBias in AIçš„æŠ¥å‘Šã€‚è¿™é‡Œä¹Ÿå°±å°†æŠ¥å‘Šçš„å¤§è‡´å†…å®¹æ¢³ç†ä¸€ä¸‹ã€‚

# Bias in Daily Life
æˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»ä¸­å°±æ— æ—¶æ— åˆ»å……æ–¥ç€åè§ã€‚æ¥ä¸‹æ¥æœ‰å‡ ä¸ªä¾‹å­è¯´æ˜ã€‚

## 1. é¦™è•‰æ˜¯ä»€ä¹ˆï¼Ÿ ğŸŒï¼Ÿ

è¿™å¼ å›¾ç‰‡ä¸Šæœ‰ä»€ä¹ˆï¼ŸWhat do you see in this picture?

![https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/Bananas.jpg](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/Bananas.jpg)

ä½ å¯èƒ½ä¼šè¯´ ... 

- é¦™è•‰
- æ ‡ç­¾
- æ‘†åœ¨å•†åº—é‡Œçš„é¦™è•‰
- æ”¾åœ¨è´§æ¶ä¸Šçš„é¦™è•‰
- å¾ˆå¤šæ†é¦™è•‰
- è´´ä¸Šæ ‡ç­¾çš„é¦™è•‰
- è´´ç€æ ‡ç­¾çš„å¾ˆå¤šæ†é¦™è•‰æ‘†åœ¨å•†åº—é‡Œçš„è´§æ¶ä¸Š
- ...

ä½†å¾ˆå°‘ä¼šæœ‰äººè¯´ï¼š

`è¿™æ˜¯â€œé»„è‰²çš„â€é¦™è•‰`

ä½†å½“çœ‹è§ä¸‹é¢è¿™ä¸¤å¼ å›¾ï¼Œæˆ‘ä»¬ä¼šè¯´è¿™æ˜¯â€œ**ç»¿è‰²çš„**â€œé¦™è•‰ã€â€œ**æˆç†Ÿçš„**â€é¦™è•‰ã€â€œ**æœ‰æ–‘ç‚¹çš„**â€é¦™è•‰ã€‚

![](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/bananas.jpg)

è¿™æ˜¯å› ä¸ºï¼Œåœ¨æˆ‘ä»¬çš„æ„è¯†é‡Œï¼Œâ€œé»„è‰²â€æ˜¯é¦™è•‰æ˜¯ä¸€ç§åŸå‹ç‰¹å¾ (prototypical)ï¼Œæ˜¯ä¸€ç§åŸºæ¨¡å’Œå¸¸è¯†ã€‚
<details>
  <summary>ä»€ä¹ˆæ˜¯Prototype?</summary>
  <br/>

* Prototype Theoryï¼šOne purpose of categorization is to **reduce the infinite differences** among stimuli **to** behaviourally and **cognitively usable proportions**
* There may be some central, prototypical notions of items that arise from stored typical properties for an object category (Rosch, 1975)
* May also store exemplars (Wu & Barsalou, 2009)
</details>

<br/>

## 2. A Simple Cognitive Test...

ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„è®¤çŸ¥æµ‹è¯•ï¼š

å°æ˜çš„çˆ¶äº²å¼€ç€ä¸€å®¶æ‚è´§åº—ã€‚ä¸€å¤©ï¼Œå°æ˜ä»çˆ¶äº²çš„æ‚è´§åº—å‡ºæ¥åè¢«ä¸€è¾†è¿é¢å¼€æ¥çš„è½¦æ’å€’ã€‚ä»–è¢«é€åˆ°äº†åŒ»é™¢çš„æ€¥è¯Šå®¤ã€‚åœ¨æ‰‹æœ¯å°ä¸Šï¼Œå¤–ç§‘åŒ»ç”Ÿå¿½ç„¶å‘ç°ï¼Œæ‰‹æœ¯å°ä¸Šèººçš„ç«Ÿæ˜¯è‡ªå·±çš„å„¿å­ã€‚è¯·é—®å°æ˜ä¸å¤–ç§‘åŒ»ç”Ÿä¹‹é—´æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ

<details>
  <summary>è¿™æ˜¯å‡ ç§å¯èƒ½çš„å›ç­”ï¼š</summary>
  <br/>

1. çˆ¶å­å…³ç³»ï¼ˆhe has two dadsï¼‰
2. æ¯å­å…³ç³»ï¼ˆhe has a mother who's a doctorï¼‰
</details>
<br/>

å¦‚æœä½ ä¸èƒ½è¿…é€Ÿè€Œå‡†ç¡®åœ°å›ç­”ä¸Šé¢çš„é—®é¢˜ï¼Œææ€•å°±æ˜¯åŸºæ¨¡å½±å“äº†è®¤çŸ¥åˆ¤æ–­è¿‡ç¨‹ã€‚ä½ éœ€è¦ä»”ç»†å®¡è§†ä¸€ä¸‹è‡ªå·±çš„æ€ç»´è¿‡ç¨‹ï¼šå¾ˆå¯èƒ½é—®é¢˜å‡ºåœ¨ä½ æ ¹æ®â€œå¸¸è¯†â€ï¼Œåšäº†ä¸€ä¸ªè™šå‡çš„å‰æå‡è®¾ä¸€ä¸€å¤–ç§‘åŒ»ç”Ÿéƒ½æ˜¯ç”·æ€§ã€‚

![Doctor & Female doctor](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/doctor%20&%20famale%20doctor.jpg)

äº‹å®ä¸Šï¼Œå¤§éƒ¨åˆ†çš„æµ‹è¯•è€…éƒ½å¿½ç•¥äº†åŒ»ç”Ÿæ˜¯å¥³æ€§çš„å¯èƒ½æ€§â€”â€”åŒ…æ‹¬ç”·äººã€å¥³äººï¼Œç”šè‡³ä¸€äº›è‡ªè®¤ä¸ºæ˜¯å¥³æ€§ä¸»ä¹‰è€…çš„äººã€‚

> The majority of test subjects overlooked the possibility that the doctor is a she - including men, women, and self-described feminists.

â€”â€” [Wapman & Belle, Boston University](https://www.bu.edu/today/2014/bu-research-riddle-reveals-the-depth-of-gender-bias/)

## 3. Word Learning from Text

æˆ‘ä»¬è°ˆè®ºäº‹ç‰©æ—¶å°±ä¼šä¸è‡ªè§‰åœ°åšå‡ºå‡è®¾ï¼Œå®ƒå¹¶ä¸ä¸€å®šå¸¦æœ‰è´Ÿé¢çš„æ„å›¾ï¼Œä½†è¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šè¯´æ˜äº†äº‹ç‰©çš„æ¦‚å¿µæ˜¯å¦‚ä½•åœ¨æˆ‘ä»¬å¤´è„‘ä¸­å‚¨å­˜è¡¨ç¤ºçš„ï¼Œä¹Ÿåæ˜ äº†æˆ‘ä»¬åœ¨ä¸–ç•Œä¸Šäº’åŠ¨æ—¶æ˜¯å¦‚ä½•è·å¾—è¿™äº›æ¦‚å¿µè¡¨ç¤ºçš„ã€‚

è¿™ä¹Ÿä¼šå½±å“æˆ‘ä»¬åœ¨æ–‡æœ¬ä¸­è®­ç»ƒçš„ç»“æœã€‚

è¿™æ˜¯ä¸€ä»½2013å¹´çš„å·¥ä½œ[1]ï¼š

Word | Frequency in corpus
--- | ---
â€œspokeâ€ | 11,577,917
â€œlaughedâ€ | 3,904,519
â€œmurderedâ€ | 2,834,529
â€œinhaledâ€ | 984,613
â€œbreathedâ€ | 725,034
â€œhuggedâ€ | 610,040
â€œblinkedâ€ | 390,692
â€œexhaleâ€ | 168,985

å¯ä»¥å‘ç°â€œmurderedâ€(è°‹æ€)çš„é¢‘ç‡è¿œå¤§äºâ€œbreathedâ€(å‘¼å¸)å’Œâ€œblinkedâ€(çœ¨çœ¼ç›)çš„é¢‘ç‡ã€‚ä½†åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ï¼Œåä¸¤è€…çš„å‘ç”Ÿçš„é¢‘ç‡ä¼šè¿œé«˜äºå‰è€…ã€‚äººä»¬æ€»æ˜¯å€¾å‘äºå¿½ç•¥ä¸€äº›ç”Ÿæ´»ä¸­ä¸è¨€è€Œå–»çš„äº‹æƒ…ã€‚

æ ¹æ®ç¥ç»ç½‘ç»œçš„ç‰¹æ€§ï¼Œè¾“å‡ºâ€œmurderedâ€çš„æ¦‚ç‡ä¼šè¿œè¶…äºåä¸¤ä¸ªè¯ã€‚

è¿™ç§ç°è±¡è¢«ç§°ä¸º**Human Reporting Biasã€‚**

> The frequency with which people write about actions, outcomes, or properties is not a reflection of real-world frequencies or the degree to which a property is characteristic of a class of individuals.

äººç±»å…³äºè¡Œä¸ºã€ç»“æœæˆ–å±æ€§çš„è¾“å‡ºé¢‘ç‡å¹¶ä¸æ˜¯çœŸå®ä¸–ç•Œé¢‘ç‡çš„åæ˜ ï¼Œä¹Ÿå¹¶ä¸ä¸€å®šæ˜¯ä¸€ç±»äº‹ç‰©çš„çœŸå®ç‰¹å¾ã€‚

## è¿™ç§åè§ï¼Œå…¶å®èµ·æºäºæˆ‘ä»¬çš„è®¤çŸ¥ã€‚

`BIAS = BAD ??`

è¿™é‡Œå¿…é¡»è¦æ¾„æ¸…çš„æ˜¯ï¼Œåè§å¹¶ä¸ä¸€å®šæ˜¯ä¸€ä»¶åäº‹æƒ…ã€‚

å¦‚æœè¦è€ƒè™‘æ‰€æœ‰æƒ…å†µçš„æ’åˆ—ç»„åˆï¼Œæˆ‘ä»¬çš„å¤§è„‘å¯èƒ½å·²ç»çˆ†ç‚¸ğŸ¤¯ğŸ¤¯ğŸ¤¯äº†ã€‚æœ‰æ—¶å€™æ­£å› ä¸ºæˆ‘ä»¬æ‹¥æœ‰ç€ä¸€éƒ¨åˆ†åè§ï¼Œæˆ‘ä»¬æ‰å¯ä»¥åº”å¯¹è¿™ä¸–ä¸Šå„å¼å„æ ·ä¸åŒçš„äº‹ç‰©ï¼Œèƒ½å¤ŸæŠŠå®ƒä»¬å˜æ¢ä¸ºå¯ä»¥åœ¨ç°å®ç”Ÿæ´»ä¸­æ“ä½œæ—¶å¯æ§åˆ¶çš„ä¸œè¥¿ã€‚

> It's a trick our minds play on us in order to help us process the world.

æ‰€ä»¥ï¼Œåè§å…¶å®æ˜¯æœ‰å¥½æœ‰åçš„ã€‚

`â€œBiasâ€ can be Good, Bad, Neutral`

# Bias in Training AI

## æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå°±å……æ–¥ç€åè§(Bias)

é¦–å…ˆè®©æˆ‘ä»¬å›å¿†ä¸€ä¸‹AIçš„è®­ç»ƒè¿‡ç¨‹ï¼š

1. æ”¶é›†å’Œæ ‡æ³¨è®­ç»ƒæ•°æ®
2. è®­ç»ƒæ¨¡å‹
3. ç­›é€‰ã€æ’åºã€èšåˆæˆ–ç”Ÿæˆç»“æœ
4. è¾“å‡º

è¿™å…¶ä¸­çš„æ¯ä¸€ä¸ªæ­¥éª¤éƒ½å……æ»¡ç€äººç±»åè§ï¼š

![https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/bias%20training.jpg](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/bias%20training.jpg)

è€Œåè§è¿˜ä¼šå½¢æˆåé¦ˆå¾ªç¯ã€‚è¿™è¢«ç§°ä¸º **Bias Network Effect** æˆ–è€… **Bias â€œLaunderingâ€**ã€‚

## Bias in Data

äººç±»æ•°æ®å»¶ç»­äº†äººç±»çš„åè§ã€‚å½“MLä»äººç±»æ•°æ®ä¸­å­¦ä¹ æ—¶ï¼Œç»“æœæ˜¯ä¸€ä¸ªåç½®ç½‘ç»œæ•ˆåº”ã€‚

å¸¸è§çš„åè§æœ‰ï¼š

![https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/human%20bias.jpg](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/human%20bias.jpg)

more in : [https://developers.google.com/machine-learning/glossary/](https://developers.google.com/machine-learning/glossary/)

- Reporting bias (æŠ¥å‘Šåè§)ï¼šäººä»¬æŠ¥å‘Šçš„å¹¶ä¸æ˜¯çœŸå®ä¸–ç•Œé¢‘ç‡çš„åæ˜ 
- Selection Bias (é€‰æ‹©åå·®)ï¼šäººä»¬çš„é€‰æ‹©å¹¶ä¸æ€»æ˜¯éšæœºæ ·æœ¬
- Out-group homogeneity bias (å¤–ç¾¤ä½“åŒè´¨æ€§åè§)ï¼šåœ¨æ¯”è¾ƒæ€åº¦ã€ä»·å€¼è§‚ã€æ€§æ ¼ç‰¹å¾å’Œå…¶ä»–ç‰¹å¾æ—¶ï¼Œäººä»¬å€¾å‘äºè®¤ä¸ºå¤–ç¾¤ä½“(outgroup)æˆå‘˜æ¯”å†…ç¾¤ä½“æˆå‘˜(ingroup)æ›´ç›¸ä¼¼ã€‚

Bias in Dataå¯¼è‡´çš„ç»“æœæœ‰ï¼š

- å…·æœ‰åå·®çš„æ•°æ®è¡¨ç¤º (Biased Data Representation)
- å…·æœ‰åå·®çš„æ ‡ç­¾ (Biased Labels)

## Bias in Interpretation

- Confirmation bias (ç¡®è®¤åè§)ï¼šäººä»¬å€¾å‘äºå¯»æ‰¾ã€è§£é‡Šã€æ”¯æŒå’Œå›å¿†ä¿¡æ¯ï¼Œä»¥ç¡®è®¤å…ˆå‰å­˜åœ¨çš„ä¿¡å¿µæˆ–å‡è®¾
- Overgeneralization (è¿‡åº¦æ³›åŒ–)ï¼šæ ¹æ®è¿‡äºç¬¼ç»Ÿå’Œ/æˆ–ä¸å¤Ÿå…·ä½“çš„ä¿¡æ¯å¾—å‡ºç»“è®ºï¼ˆä¹Ÿä¸è¿‡æ‹Ÿåˆæœ‰å…³ï¼‰
- Correlation fallacy (ç›¸å…³æ€§è°¬è¯¯)ï¼šæ··æ·†ç›¸å…³æ€§å’Œå› æœå…³ç³»
- Automation bias (è‡ªåŠ¨åŒ–åå·®)ï¼šäººä»¬æ›´å€¾å‘äºæ¥è‡ªè‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿçš„å»ºè®®

# Bias in AI

åœ¨AIä¸­é‡åˆ°çš„åè§å¤§è‡´å¯ä»¥åˆ†ä¸ºè¿™å‡ ç±»ï¼š

- åœ¨ç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ ä¸­çš„åå·® (Bias in statistics and ML)
    - ä¼°è®¡å€¼çš„åå·®ï¼šé¢„æµ‹å€¼ä¸æˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„æ­£ç¡®å€¼ä¹‹é—´çš„å·®å¼‚
    - â€œåå·®â€ä¸€è¯ *b* (å¦‚y = mx + b)
- è®¤çŸ¥åè§ (Cognitive biases)
    - Confirmation bias, Recency bias, Optimism bias
- ç®—æ³•ä¸­çš„åè§ (Algorithmic bias)
    - å¯¹ä¸ç§æ—ã€æ”¶å…¥ã€æ€§å–å‘ã€å®—æ•™ã€æ€§åˆ«å’Œå…¶ä»–å†å²ä¸Šä¸æ­§è§†å’Œè¾¹ç¼˜åŒ–ç›¸å…³çš„ç‰¹å¾ç›¸å…³çš„äººçš„ä¸å…¬å¹³ã€ä¸å…¬å¹³æˆ–åè§å¾…é‡ï¼Œä¼šåœ¨ç®—æ³•ç³»ç»Ÿæˆ–ç®—æ³•è¾…åŠ©å†³ç­–ä¸­ä½“ç°å‡ºæ¥ã€‚

ç¬¬ä¸€ç§çš„åå·®æ˜¯å®¢è§‚çš„å¯æ§åˆ¶çš„ï¼Œè€Œç¬¬äºŒç§åè§æ¥æºäºæˆ‘ä»¬çš„ç°å®ç”Ÿæ´»ï¼Œç®—æ³•æ— æ³•æ”¹å˜å®ƒã€‚
**ç¬¬ä¸‰ç§åè§æ˜¯éœ€è¦æˆ‘ä»¬æ³¨æ„å’Œé¿å…çš„**ã€‚AIä¸ºäººç±»æœåŠ¡ï¼Œå½“AIçš„è¾“å…¥æ¥æºäºäººç±»æä¾›çš„åè§æ•°æ®ï¼ˆå³ä½¿æ˜¯æ— æ„çš„ï¼‰ï¼Œè®¡ç®—æœºæ€»æ˜¯ä¼š**æ”¾å¤§è¿™ç§åè§çš„æƒ³æ³•**ã€‚

> Although neural networks might be said to write their own programs, they do so towards goals set by humans, using data collected for human purposes. If the data is skewed, even by accident, the computers will **amplify injustice**.

[â€”â€” The Guardian](https://www.theguardian.com/commentisfree/2016/oct/23/the-guardian-view-on-machine-learning-people-must-decide)

## Why Cannot We Amplify Injustice? 

ä¸ºä»€ä¹ˆè¯´æ”¾å¤§åè§æ˜¯ä¸€ä»¶ä¸å¥½çš„äº‹æƒ…ï¼Ÿæ¥ä¸‹æ¥æœ‰å‡ ä¸ªç®—æ³•ä¸­æ”¾å¤§åè§çš„ä¾‹å­ã€‚

ç¬¬ä¸€ä¸ªä¾‹å­æ˜¯**é¢„æµ‹æ€§è­¦åŠ¡** (Predicting Policing)ã€‚

ç®—æ³•ä¼šé¢„æµ‹æ½œåœ¨çš„çŠ¯ç½ªçƒ­ç‚¹åŒºåŸŸï¼Œå¯ä»¥å¸®åŠ©å†³ç­–æ˜¯å¦è¦åœ¨è¯¥åŒºåŸŸå¢åŠ å†›å®˜éƒ¨ç½²ã€‚è¿™ç§ç®—æ³•æ ¹æ®ä»¥å‰æŠ¥å‘Šçš„**é€®æ•åœ°ç‚¹**ï¼ˆ**æ³¨æ„ï¼šå¹¶ä¸æ˜¯å‘ç”ŸçŠ¯ç½ªçš„åœ°ç‚¹**ï¼‰ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œä»è¿‡å»é¢„æµ‹æœªæ¥å¯èƒ½å‘ç”Ÿçš„çŠ¯ç½ªåœ°ç‚¹ã€‚
ä½†æœ‰ä¸€äº›å¯èƒ½æ˜¯çŠ¯ç½ªçš„åŒºåŸŸå¯èƒ½ä»æ¥æ²¡æœ‰è¢«æ¢ç´¢åˆ°ï¼Œè¿™éƒ¨åˆ†çš„å¯èƒ½æ€§ä¸º0ã€‚è€Œç»è¿‡æ•°æ®çš„å¾ªç¯åå¤è®­ç»ƒï¼Œè¿™ä½¿å¾—æƒ…å†µä¼šæ›´åŠ æ¶åŒ–ã€‚[2]

å¦ä¸€ä¸ªä¾‹å­æ˜¯**é‡åˆ‘è¾…åŠ©ç³»ç»Ÿ** (Predicting Sentencing)ã€‚

ç»è¿‡è®­ç»ƒï¼Œç³»ç»Ÿä¼šé»˜è®¤è®¤ä¸ºé»‘äººçš„çŠ¯ç½ªé£é™©é«˜äºç™½äººã€‚ç»è¿‡Automation Biasï¼Œè¿‡åº¦æ³›åŒ–ã€å¾ªç¯åé¦ˆå’Œç›¸å…³æ€§è°¬è¯¯ï¼Œä¸€äº›é”™è¯¯çš„ä¾‹å­åå¤å‘ç”Ÿï¼Œæœ€åå½¢æˆäº†æŸç§å› æœå…³ç³»ã€‚[3]

è¿™æ ·çš„ä¾‹å­æ•°ä¸èƒœæ•°ï¼š

- [Faception](http://www.faception.com/)æ˜¯æ˜¯ä¸€å®¶åŸºäºäººçš„é¢éƒ¨æ­ç¤ºå…¶ä¸ªæ€§çš„å…¬å¸ã€‚ä»–ä»¬å£°ç§°å¯ä»¥æä¾›ä¸“ä¸šçš„å¼•æ“ä»è„¸çš„å½¢è±¡è¯†åˆ«â€œé«˜æ™ºå•†â€ã€â€œç™½é¢†çŠ¯ç½ªâ€ã€â€œæ‹ç«¥ç™–â€,å’Œâ€œææ€–åˆ†å­â€ã€‚å…¶ä¸»è¦å®¢æˆ·ä¸ºå›½åœŸå®‰å…¨å’Œå…¬å…±å®‰å…¨ã€‚
    - ä½†Google AI çš„å·¥ä½œè¡¨æ˜ï¼Œå³ä½¿æ˜¯å˜´è§’å‘ä¸Šæˆ–å‘ä¸‹æ‰¬èµ·çš„è§’åº¦ä¹Ÿä¼šå½±å“å…¶åˆ¤æ–­ã€‚[4] (See longer piece on Medium, â€œ[Physiognomyâ€™s New Clothes](https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a)â€)
  ![](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/angle.jpg)
    - è¿™ä¸ªä¾‹å­ä¸­çš„åè§æœ‰ï¼šSelection Bias + Experimenterâ€™s Bias + Confirmation Bias + Correlation Fallacy + Feedback Loops

- æŸå·¥ä½œå£°ç§°ä»–ä»¬å‘æ˜äº†æ€§å–å‘æ¢æµ‹å™¨ï¼Œä»–ä»¬é€šè¿‡ä»çº¦ä¼šç½‘ç«™ä¸‹çˆ¬å–ä¸‹æ¥çš„35,326å¼ ç…§ç‰‡é¢„æµ‹åŒæ€§æ‹è€…ã€‚[5]
    >â€œConsistent with the prenatal hormone theory [PHT] of sexual orientation, gay men and women tended to have gender-atypical facial morphology.â€
![](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/homosexuality.jpg)
    - ä½†äº‹å®ä¸Šï¼Œåœ¨è‡ªæ‹ä¸­ï¼ŒåŒæ€§æ‹å’Œå¼‚æ€§æ‹ä¹‹é—´çš„å·®å¼‚ä¸æ‰“æ‰®ã€è¡¨ç°å’Œç”Ÿæ´»æ–¹å¼æœ‰å…³ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™æ˜¯ä¸€ç§æ–‡åŒ–çš„å·®å¼‚ï¼Œè€Œä¸æ˜¯é¢éƒ¨ç»“æ„çš„å·®å¼‚ã€‚ç”šè‡³å¯ä»¥é€šè¿‡æ„é€ ä¸€é¢—ç®€å•çš„æ‰“æ‰®ç‰¹å¾çš„å†³ç­–æ ‘æ¥åˆ¤æ–­ã€‚(See longer response on Medium, [â€œDo Algorithms Reveal Sexual Orientation or Just Expose our Stereotypes?â€](https://medium.com/@blaisea/do-algorithms-reveal-sexual-orientation-or-just-expose-our-stereotypes-d998fafdf477))
![](https://xtopia-1258297046.cos.ap-shanghai.myqcloud.com/gromming.jpg)
    -  è¿™ä¸ªä¾‹å­ä¸­çš„åè§æœ‰ï¼šSelection Bias + Experimenterâ€™s Bias + Correlation Fallacy

- ...

æ€»è€Œè¨€ä¹‹ï¼Œç®—æ³•åè§ååˆ†å¸¸è§ã€‚ä½†å¦‚æœAIåšä¸åˆ°æ— åè§ï¼Œæˆ‘ä»¬åˆæ€ä¹ˆèƒ½å¤Ÿç›¸ä¿¡ä»–ä»¬çš„åˆ¤æ–­ï¼Ÿ
é‚£ä¹ˆæˆ‘ä»¬è¯¥æ€æ ·åšï¼Œæ‰èƒ½é¿å…ç®—æ³•åè§ï¼Ÿå½“æˆ‘ä»¬åœ¨æåŠç®—æ³•å…¬å¹³æ€§çš„æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿ

---

# Reference

[1] Jonathan Gordon and Benjamin Van Durme. 2013. Reporting bias and knowledge acquisition. In Proceedings of the 2013 workshop on Automated knowledge base construction (AKBC '13). DOI:[https://doi.org/10.1145/2509558.2509563](10.1145/2509558.2509563)

[2] [Smithsonian. Artificial Intelligence Is Now Used to Predict Crime. But Is It Biased? 2018](https://www.smithsonianmag.com/innovation/artificial-intelligence-is-now-used-predict-crime-is-it-biased-180968337/)

[3] [ProPublica. Northpointe: Risk in Criminal Sentencing. 2016.](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)

[4] Xiaolin Wu, Xi Zhang: Automated Inference on Criminality using Face Images. [CoRR abs/1611.04135 (2016)](https://arxiv.org/abs/1611.04135)

[5] Wang, Yilun, and Michal Kosinski. 2017. â€œDeep Neural Networks Are More Accurate Than Humans at Detecting Sexual Orientation from Facial Images.â€ PsyArXiv. September 7. doi:[10.1037/pspa0000098](https://psyarxiv.com/hv28a/).